<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://shredlabcmu.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://shredlabcmu.github.io/" rel="alternate" type="text/html" /><updated>2025-12-22T11:00:39-05:00</updated><id>https://shredlabcmu.github.io/feed.xml</id><title type="html">SHREDLab</title><subtitle>Researching haptic technologies with social and educational impact at Carnegie Mellon University
</subtitle><entry><title type="html">PhD Defense: Sarah Costrell</title><link href="https://shredlabcmu.github.io/Sarah-Defense/" rel="alternate" type="text/html" title="PhD Defense: Sarah Costrell" /><published>2025-12-16T07:00:00-05:00</published><updated>2025-12-16T07:00:00-05:00</updated><id>https://shredlabcmu.github.io/SarahDefense</id><content type="html" xml:base="https://shredlabcmu.github.io/Sarah-Defense/">&lt;p&gt;Congratulations to Dr. Costrell who has successfully defended her PhD Thesis!&lt;/p&gt;

&lt;p&gt;Her dissertation presents novel soft materials-based approaches using magnetism to create compelling touch experiences, in particular, the development of soft, flexible composites made from oil-based polymers mixed with magnetic particles that behave as actuators in an external magnetic field. These materials have been integrated into wearable fingertip sheaths that produce haptic cues in response to driving magnetic forces, allowing users to feel virtual textural sensations. The culmination of this research is in a device called MAGTRACE (MAGnetic Texture Rendering for Active Contact and Exploration) that lets users actively explore various dynamically rendered macroscale virtual textures. Initial human studies showed that using only the sheaths and a single electromagnet, participants could clearly discern variations in the applied magnetic signal magnitude, enabling communication of a range of haptic sensation levels. A follow-on study with MAGTRACE showed that users could accurately identify different waveform shapes at varying sizes, validating device rendering of discernible macroscale haptic textures. These results demonstrate that this new class of soft magnetic wearables constitutes an effective device design paradigm for applications in virtual reality and teleoperation.&lt;/p&gt;

&lt;p&gt;You can read her thesis here: &lt;a href=&quot;/papers/Sarah_Costrell_PhD_Thesis.pdf&quot;&gt;Sarah Costrell PhD Thesis&lt;/a&gt;&lt;/p&gt;

&lt;!-- You can visit her thesis work at: [https://www.ri.cmu.edu/publications/robotic-system-design-principles-for-human-human-collaboration/](https://www.ri.cmu.edu/publications/robotic-system-design-principles-for-human-human-collaboration/) --&gt;

&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-12-14-sarah-defense/sarahscommitte.jpeg&quot; /&gt;
    &lt;figcaption&gt;
        Sarah and her Thesis Committee: From left to right Carmel Majidi, Sarah Costrell, Melisa Orta Martinez, Daphne Chan and Roberta Klatzky.   &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- ## Contact

 - [William Scott](/team/will/) &lt;wscott2 [at] cmu [dot] edu&gt; --&gt;</content><author><name>SHRED Lab</name></author><category term="highlights" /><summary type="html">Congratulations to Dr. Costrell who has successfully defended her PhD Thesis!</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://shredlabcmu.github.io/img/posts/2025-12-14-sarah-defense/sarahscommitte.jpeg" /><media:content medium="image" url="https://shredlabcmu.github.io/img/posts/2025-12-14-sarah-defense/sarahscommitte.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">PhD Defense: Samantha Speer</title><link href="https://shredlabcmu.github.io/Sam-Defense/" rel="alternate" type="text/html" title="PhD Defense: Samantha Speer" /><published>2025-12-14T07:00:00-05:00</published><updated>2025-12-14T07:00:00-05:00</updated><id>https://shredlabcmu.github.io/SamDefense</id><content type="html" xml:base="https://shredlabcmu.github.io/Sam-Defense/">&lt;p&gt;Congratulations to Dr. Speer who has successfully defended her PhD Thesis!&lt;/p&gt;

&lt;p&gt;Her thesis entitled “Robotic System Design Principles for Human-Human Collaboration”,  investigates how robots can be designed to support collaboration between users during assembly tasks. Drawing from cognitive theories used in the disciplines of Computer-Supported Collaborative Work (CSCW), Computer-Supported Collaborative Learning (CSCL), Educational Robotics, and Human-Robot Interaction (HRI), it establishes a set of theoretically grounded design principles. I present the empirically validated effect of these design principles on collaboration during various assembly tasks.&lt;/p&gt;

&lt;p&gt;You can visit her thesis work at: &lt;a href=&quot;https://www.ri.cmu.edu/publications/robotic-system-design-principles-for-human-human-collaboration/&quot;&gt;https://www.ri.cmu.edu/publications/robotic-system-design-principles-for-human-human-collaboration/&lt;/a&gt;&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-12-14-sam-defense/sam-defense.jpg&quot; /&gt;
    &lt;figcaption&gt;
        Sam and her Thesis Committee: From left to right Sam Speer, Jim McCann, Melisa Orta Martinez, Illah Nourbakhsh and Kylie Peppler (joining us virtually).   &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- ## Contact

 - [William Scott](/team/will/) &lt;wscott2 [at] cmu [dot] edu&gt; --&gt;</content><author><name>SHRED Lab</name></author><category term="highlights" /><summary type="html">Congratulations to Dr. Speer who has successfully defended her PhD Thesis!</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://shredlabcmu.github.io/img/posts/2025-12-14-sam-defense/sam-defense.jpg" /><media:content medium="image" url="https://shredlabcmu.github.io/img/posts/2025-12-14-sam-defense/sam-defense.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Soft Magnetic Actuator</title><link href="https://shredlabcmu.github.io/research/soft/" rel="alternate" type="text/html" title="Soft Magnetic Actuator" /><published>2025-02-03T05:40:07-05:00</published><updated>2025-02-03T05:40:07-05:00</updated><id>https://shredlabcmu.github.io/research/soft-magnetic-actuators</id><content type="html" xml:base="https://shredlabcmu.github.io/research/soft/">&lt;p&gt;Soft Magnetic Actuator for Haptics.&lt;/p&gt;

&lt;p&gt;Current tactile haptic displays are either able to render tangential and normal forces in one area of actuation on the fingertip, or normal forces in multiple areas of independent actuation, but cannot provide different kinds of forces in multiple independent areas of actuation. We are currently fabricating actuators using very low modulus materials together with magnetic particles to create weakly polarized flexible magnets. These materials respond with attraction or repulsion depending on the direction of the applied magnetic field and can apply shear or normal forces depending on the placement of external electromagnets. We are also developing apparatuses in which to test these materials for efficacy in texture rendering.&lt;/p&gt;

&lt;figure&gt;
 &lt;img src=&quot;/img/posts/2022-11-08-soft-magnetic-actuators/fingertip_and_magnets.png&quot; alt=&quot;Tiltrotor VTOL&quot; /&gt;
&lt;/figure&gt;

&lt;!-- &lt;div class=&quot;video-wrapper&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/KCBxeJupIgk&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt; --&gt;
&lt;!-- &lt;div class=&quot;video-wrapper&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/KCBxeJupIgk&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt; --&gt;
&lt;div class=&quot;video-wrapper&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/KCBxeJupIgk&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;

&lt;h3 id=&quot;publications&quot;&gt;Publications&lt;/h3&gt;
&lt;p&gt;A Magnetic Soft Device for Tactile Haptic Actuation of the Fingertip.
By Costrell, S., Alam, M., Klatzky, R.L., McHenry, M.E., Walker, L.M. and Martinez, M.O. In 2023 IEEE World Haptics Conference (WHC), , pp. 48–55, , 2023. &lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/10224478&quot;&gt;IEEXplore link&lt;/a&gt;&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2022-11-08-soft-magnetic-actuators/user_study_setup.jpg&quot; /&gt;
    &lt;figcaption&gt;
       Setup for user study testing.
    &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2022-11-08-soft-magnetic-actuators/closer_magnet_ruler.gif&quot; /&gt;
    &lt;figcaption&gt;
        Interaction with the magnetic field.
    &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;contact&quot;&gt;Contact&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Sarah Costrell (MechE) &lt;a href=&quot;mailto:scostrel@andrew.cmu.edu&quot;&gt;(scostrel@andrew.cmu.edu)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>SHRED Lab</name></author><category term="research" /><summary type="html">Soft Magnetic Actuator for Haptics.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://shredlabcmu.github.io/img/posts/2022-11-08-soft-magnetic-actuators/fingertipandmagnet.jpg" /><media:content medium="image" url="https://shredlabcmu.github.io/img/posts/2022-11-08-soft-magnetic-actuators/fingertipandmagnet.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">RoboLoom: Teach math through weaving</title><link href="https://shredlabcmu.github.io/research/roboloom-2025/" rel="alternate" type="text/html" title="RoboLoom: Teach math through weaving" /><published>2025-02-03T05:40:07-05:00</published><updated>2025-02-03T05:40:07-05:00</updated><id>https://shredlabcmu.github.io/research/roboloom</id><content type="html" xml:base="https://shredlabcmu.github.io/research/roboloom-2025/">&lt;p&gt;RoboLoom is a robotic Jacquard loom kit designed to facilitate interdisciplinary learning in engineering, mathematics, and art through collaborative assembly and use. It allows students to work together on building and operating the loom, fostering teamwork while teaching key concepts in weaving, engineering, and linear algebra.
Most people don’t know how closely related computers, matrices, and the craft of weaving are, but weaving patterns and early loom designs inspired some of early computing and matrices. For today’s looms and computers there is still a connection. Matrices can describe how a loom is threaded, and what actions are taken each time step while weaving. These matrices can then be multiplied together resulting in a cloth’s pattern. Designing and optimizing these matrices can be explored as a computational problem in a crafting framework. 
In addition, the woven cloth itself can be engineered using mathematical properties of the matrix representation of the cloth. These physical properties can predict how the cloth can be used and the strength it will have. Furthermore, advancements in engineering have been inspired by looms as they’ve been engineered to hold tension and become more autonomous machines. 
RoboLoom aims to explore these interrelated concepts and bring weaving, matrix math, and engineering together in the classroom in new and interesting ways.&lt;/p&gt;

&lt;!-- &lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-02-03-roboloom/roboloom_side_unedited.jpg&quot; /&gt;
    &lt;figcaption&gt;
        RoboLoom assembled.
    &lt;/figcaption&gt;
&lt;/figure&gt; --&gt;
&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-02-03-roboloom/students_working.png&quot; /&gt;
    &lt;figcaption&gt;
        Students working during the summer of 2024.
    &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-02-03-roboloom/RoboLooms_Class_S24.jpg&quot; /&gt;
    &lt;figcaption&gt;
        Render of the RoboLoom.
    &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-02-03-roboloom/tension_system.jpg&quot; /&gt;
    &lt;figcaption&gt;
        Roboloom tension system.
    &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-02-03-roboloom/JacquardMode Herringbone.png&quot; /&gt;
    &lt;figcaption&gt;
        GUI for weaving using our RoboLoom.
    &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;contact&quot;&gt;Contact&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/team/sam&quot;&gt;Samantha Speer&lt;/a&gt; snspeer@andrew.cmu.edu&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/team/will/&quot;&gt;Will Scott&lt;/a&gt; wscott2@andrew.cmu.edu&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Our dedicated website at: &lt;a href=&quot;https://sites.google.com/view/roboloom/&quot;&gt;https://sites.google.com/view/roboloom/&lt;/a&gt;&lt;/p&gt;</content><author><name>SHRED Lab</name></author><category term="research" /><summary type="html">RoboLoom is a robotic Jacquard loom kit designed to facilitate interdisciplinary learning in engineering, mathematics, and art through collaborative assembly and use. It allows students to work together on building and operating the loom, fostering teamwork while teaching key concepts in weaving, engineering, and linear algebra. Most people don’t know how closely related computers, matrices, and the craft of weaving are, but weaving patterns and early loom designs inspired some of early computing and matrices. For today’s looms and computers there is still a connection. Matrices can describe how a loom is threaded, and what actions are taken each time step while weaving. These matrices can then be multiplied together resulting in a cloth’s pattern. Designing and optimizing these matrices can be explored as a computational problem in a crafting framework. In addition, the woven cloth itself can be engineered using mathematical properties of the matrix representation of the cloth. These physical properties can predict how the cloth can be used and the strength it will have. Furthermore, advancements in engineering have been inspired by looms as they’ve been engineered to hold tension and become more autonomous machines. RoboLoom aims to explore these interrelated concepts and bring weaving, matrix math, and engineering together in the classroom in new and interesting ways.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://shredlabcmu.github.io/img/posts/2025-02-03-roboloom/RoboLoom.jpg" /><media:content medium="image" url="https://shredlabcmu.github.io/img/posts/2025-02-03-roboloom/RoboLoom.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">16-880: Engineering Haptic Interfaces</title><link href="https://shredlabcmu.github.io/teaching/ehi/" rel="alternate" type="text/html" title="16-880: Engineering Haptic Interfaces" /><published>2025-02-02T07:00:00-05:00</published><updated>2025-02-02T07:00:00-05:00</updated><id>https://shredlabcmu.github.io/teaching/ehi</id><content type="html" xml:base="https://shredlabcmu.github.io/teaching/ehi/">&lt;p&gt;This course focuses on addressing challenges in the field of haptics from an engineers perspective. We will begin by studying human haptic perception and an introduction into psychophysics. We will then study the design and control of haptic systems which provide touch feedback to a user. The class format will include lectures, discussion, paper presentations, laboratories and assignments using hardware that will be shipped to the students, and a class project. This class is designed to be a graduate/advanced undergraduate course and requires a background in dynamic systems, mechatronics, and basic programming. Mechanical prototyping, robotics, and feedback control knowledge are useful skills for this class but are not required.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-02-04-ehi/haptics.png&quot; /&gt;
    &lt;!-- &lt;figcaption&gt;
        Students working at the Hazelwood library.
    &lt;/figcaption&gt; --&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;instructor&quot;&gt;Instructor&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/_team/melisa&quot;&gt;Melisa Orta Martinez&lt;/a&gt; - &lt;a href=&quot;mailto:mortamar.andrew.cmu.edu&quot;&gt;mortamar@andrew.cmu.edu&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Melisa Orta Martinez</name></author><category term="teaching" /><summary type="html">This course focuses on addressing challenges in the field of haptics from an engineers perspective. We will begin by studying human haptic perception and an introduction into psychophysics. We will then study the design and control of haptic systems which provide touch feedback to a user. The class format will include lectures, discussion, paper presentations, laboratories and assignments using hardware that will be shipped to the students, and a class project. This class is designed to be a graduate/advanced undergraduate course and requires a background in dynamic systems, mechatronics, and basic programming. Mechanical prototyping, robotics, and feedback control knowledge are useful skills for this class but are not required.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://shredlabcmu.github.io/img/posts/2025-02-04-ehi/haptics.png" /><media:content medium="image" url="https://shredlabcmu.github.io/img/posts/2025-02-04-ehi/haptics.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">16-224 IDeATe: Re-Crafting Computational Thinking with Soft Technologies</title><link href="https://shredlabcmu.github.io/teaching/ideate/" rel="alternate" type="text/html" title="16-224 IDeATe: Re-Crafting Computational Thinking with Soft Technologies" /><published>2025-02-02T07:00:00-05:00</published><updated>2025-02-02T07:00:00-05:00</updated><id>https://shredlabcmu.github.io/teaching/ideate-soft</id><content type="html" xml:base="https://shredlabcmu.github.io/teaching/ideate/">&lt;p&gt;Re-Crafting Computational Thinking with Soft Technologies focuses on teaching introductory concepts of Robotics, Mechatronics, and Computer Science using an arts-based approach. During the course, you will build a weaving robot, program it, and explore how weaving is connected to computer programming and matrix mathematics. You will also learn the history of weaving, how to design dynamic patterns, and how to extract the features of those patterns into mathematical equations and computer programs.&lt;/p&gt;

&lt;!-- This course included guest presentations from:

Kate O’Brien
Vernelle Noel
Sarah Khadraoui
Harrison Apple
Mygenet Harris --&gt;

&lt;p&gt;This course serves students with an interest in computer programming, mechatronics, and robotics, offering a unique interdisciplinary approach to these concepts. It is equally valuable for those with a passion for textiles, weaving, and art who aim to discover the intriguing connections between weaving, mathematics, and robotics. Our target audience encompasses students from various academic backgrounds, with a particular focus on attracting individuals from the College of Fine Arts and the Computer Science departments. Previously, the course has been offered once as a mini-course, and the enrolled students represented a diverse range of majors, including: Art History, Architecture, Electrical Engineering, Computer Science, Art.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-02-04-ideate-soft/hands-soft.jpeg&quot; /&gt;
    &lt;!-- &lt;figcaption&gt;
        Students working at the Hazelwood library.
    &lt;/figcaption&gt; --&gt;
&lt;/figure&gt;

&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-02-04-ideate-soft/collaboration.jpeg&quot; /&gt;
    &lt;!-- &lt;figcaption&gt;
        Students working at the Hazelwood library.
    &lt;/figcaption&gt; --&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;instructor&quot;&gt;Instructor&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/_team/melisa&quot;&gt;Melisa Orta Martinez&lt;/a&gt; - &lt;a href=&quot;mailto:mortamar.andrew.cmu.edu&quot;&gt;mortamar@andrew.cmu.edu&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://ideate.cmu.edu/about/people/participating-educators/olivia-robinson.html&quot;&gt;Olivia Robinson&lt;/a&gt; - &lt;a href=&quot;mailto:orobinso@andrew.cmu.edu&quot;&gt;orobinso@andrew.cmu.edu&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Melisa Orta Martinez</name></author><category term="teaching" /><summary type="html">Re-Crafting Computational Thinking with Soft Technologies focuses on teaching introductory concepts of Robotics, Mechatronics, and Computer Science using an arts-based approach. During the course, you will build a weaving robot, program it, and explore how weaving is connected to computer programming and matrix mathematics. You will also learn the history of weaving, how to design dynamic patterns, and how to extract the features of those patterns into mathematical equations and computer programs.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://shredlabcmu.github.io/img/posts/2025-02-04-ideate-soft/hands-soft.jpeg" /><media:content medium="image" url="https://shredlabcmu.github.io/img/posts/2025-02-04-ideate-soft/hands-soft.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Rescue Rollers</title><link href="https://shredlabcmu.github.io/research/rescue-rollers/" rel="alternate" type="text/html" title="Rescue Rollers" /><published>2025-02-01T07:00:00-05:00</published><updated>2025-02-01T07:00:00-05:00</updated><id>https://shredlabcmu.github.io/research/rescue-rollers</id><content type="html" xml:base="https://shredlabcmu.github.io/research/rescue-rollers/">&lt;p&gt;Rescue Rollers are centimeter scale robots designed to operate in unstructured environments for search and rescue. We are exploring how we can achieve robust locomotion with robots of this size after natural disasters. By leveraging their size and a suite of sensing capabilities, a swarm of Rescue Rollers can help first-responders safely and efficiently locate and recover survivors. Rescue Rollers are also part of a symbiotic system with vine robots. They provide steering and enhanced sensing capabilities, while the vine robots allow for efficient large scale locomotion and power for the centi-robots.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-02-01-rescue-rollers/ExplodedIsometric.png&quot; /&gt;
    &lt;!-- &lt;img src=&quot;/img/posts/2022-05-02-haptic-blind/DeltaMech.png&quot; /&gt; --&gt;
    &lt;figcaption&gt;
        Exploded Isometric View of our Rescue Roller.
    &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-02-01-rescue-rollers/Deploy.png&quot; /&gt;
    &lt;!-- &lt;img src=&quot;/img/posts/2022-05-02-haptic-blind/DeltaMech.png&quot; /&gt; --&gt;
    &lt;figcaption&gt;
       Deployment of our rescue roller using via Vine Robot.
    &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;!-- &lt;div class=&quot;video-wrapper&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/cMkF67OGzsE&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt; --&gt;
&lt;!-- &lt;div class=&quot;video-wrapper&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/eGMqdWkUY98&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt; --&gt;
&lt;!-- https://youtube.com/shorts/eGMqdWkUY98?feature=share --&gt;

&lt;h3 id=&quot;contact&quot;&gt;Contact&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/team/sidney/&quot;&gt;Sidney Nimako&lt;/a&gt; -  &lt;a href=&quot;mailto:snimakob@andrew.cmu.edu&quot;&gt;snimakob@andrew.cmu.edu&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/team/melisa/&quot;&gt;Melisa Orta Martinez&lt;/a&gt; - &lt;a href=&quot;mailto:mortamar@andrew.cmu.edu&quot;&gt;mortamar@andrew.cmu.edu&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>SHRED Lab</name></author><category term="research" /><summary type="html">Rescue Rollers are centimeter scale robots designed to operate in unstructured environments for search and rescue. We are exploring how we can achieve robust locomotion with robots of this size after natural disasters. By leveraging their size and a suite of sensing capabilities, a swarm of Rescue Rollers can help first-responders safely and efficiently locate and recover survivors. Rescue Rollers are also part of a symbiotic system with vine robots. They provide steering and enhanced sensing capabilities, while the vine robots allow for efficient large scale locomotion and power for the centi-robots.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://shredlabcmu.github.io/img/posts/2025-02-01-rescue-rollers/soft_rescue.png" /><media:content medium="image" url="https://shredlabcmu.github.io/img/posts/2025-02-01-rescue-rollers/soft_rescue.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Cooperative Exploration with Heterogeneous Robot Teams</title><link href="https://shredlabcmu.github.io/research/cooperative/" rel="alternate" type="text/html" title="Cooperative Exploration with Heterogeneous Robot Teams" /><published>2025-02-01T07:00:00-05:00</published><updated>2025-02-01T07:00:00-05:00</updated><id>https://shredlabcmu.github.io/research/cooperative-robots</id><content type="html" xml:base="https://shredlabcmu.github.io/research/cooperative/">&lt;p&gt;We investigate how a heterogeneous robot team can improve urban search and rescue methods in collapsed buildings caused by earthquakes. Two types of robots compose the team: a vine robot for climbing in narrow, vertical spaces and RESCUE Rollers for general mobility at a minimal cost. The unstructured nature of disaster sites demands diverse robotic capabilities to traverse narrow gaps, navigate fallen rubble, and collectively analyze their environment to provide optimal coverage. Through various simulations and experiments, we evaluate different team compositions and compare trade-offs with regard to cost versus coverage. These experiments highlight the benefits of combining varied robot types to formulate a team that can adapt to the many challenges in unstructured environments. Building on these insights, we will next conduct real life experiments and create navigation policies leveraging the robot team’s collaboration.&lt;/p&gt;

&lt;!-- &lt;figure&gt;
 &lt;img src=&quot;/img/posts/2022-03-07-haptic-guidance/Hand_render.JPG&quot;/&gt;
&lt;/figure&gt; --&gt;
&lt;div class=&quot;video-wrapper&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/rR4xNo3OONY&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;

&lt;h3 id=&quot;contact&quot;&gt;Contact&lt;/h3&gt;
&lt;!-- - [Woongseok (Michael) Han](https://shredlabcmu.github.io/team/michael/) (woongseh [at]andrew [dot] cmu [dot] edu)  --&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/team/guadalupe&quot;&gt;Guadalupe Bernal&lt;/a&gt; - &lt;a href=&quot;mailto:gbernal@andrew.cmu.edu&quot;&gt;gbernal@andrew.cmu.edu&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/team/melisa/&quot;&gt;Melisa Orta Martinez&lt;/a&gt; - &lt;a href=&quot;mailto:mortamar.andrew.cmu.edu&quot;&gt;mortamar@andrew.cmu.edu&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>SHRED Lab</name></author><category term="research" /><summary type="html">We investigate how a heterogeneous robot team can improve urban search and rescue methods in collapsed buildings caused by earthquakes. Two types of robots compose the team: a vine robot for climbing in narrow, vertical spaces and RESCUE Rollers for general mobility at a minimal cost. The unstructured nature of disaster sites demands diverse robotic capabilities to traverse narrow gaps, navigate fallen rubble, and collectively analyze their environment to provide optimal coverage. Through various simulations and experiments, we evaluate different team compositions and compare trade-offs with regard to cost versus coverage. These experiments highlight the benefits of combining varied robot types to formulate a team that can adapt to the many challenges in unstructured environments. Building on these insights, we will next conduct real life experiments and create navigation policies leveraging the robot team’s collaboration.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://shredlabcmu.github.io/img/posts/2025-02-04-cooperative-robots/cooperative.png" /><media:content medium="image" url="https://shredlabcmu.github.io/img/posts/2025-02-04-cooperative-robots/cooperative.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">HaptiClay: Crafting Polynomial Functions</title><link href="https://shredlabcmu.github.io/research/hapticlay/" rel="alternate" type="text/html" title="HaptiClay: Crafting Polynomial Functions" /><published>2025-01-02T07:00:00-05:00</published><updated>2025-01-02T07:00:00-05:00</updated><id>https://shredlabcmu.github.io/research/hapticlay</id><content type="html" xml:base="https://shredlabcmu.github.io/research/hapticlay/">&lt;p&gt;HaptiClay, a low-cost kinesthetic haptic interface that elevates the understanding of mathematics language by providing embodied non-verbal representations of math concepts. 
Our interface integrates four key components: a haptic device, a high-level simulation that communicates with a low-level controller for force and position updates, a low-level controller that executes the feedback from the simulation, and a visualization system that provides visual feedback corresponding to the haptic input.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-01-02-hapticlay/will.png&quot; /&gt;
    &lt;figcaption&gt;
        Student crafting a quadratic function using HaptiClay
    &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;contact&quot;&gt;Contact&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;/team/iqui&quot;&gt;Iqui Balam Heredia Marin&lt;/a&gt; - &lt;a href=&quot;mailto:iquibalh@andrew.cmu.edu&quot;&gt;iquibalh@andrew.cmu.edu&lt;/a&gt;&lt;/p&gt;</content><author><name>SHRED Lab</name></author><category term="research" /><summary type="html">HaptiClay, a low-cost kinesthetic haptic interface that elevates the understanding of mathematics language by providing embodied non-verbal representations of math concepts. Our interface integrates four key components: a haptic device, a high-level simulation that communicates with a low-level controller for force and position updates, a low-level controller that executes the feedback from the simulation, and a visualization system that provides visual feedback corresponding to the haptic input.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://shredlabcmu.github.io/img/posts/2025-01-02-hapticlay/will.png" /><media:content medium="image" url="https://shredlabcmu.github.io/img/posts/2025-01-02-hapticlay/will.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Robot-Mediated haptics for blind students STEM education</title><link href="https://shredlabcmu.github.io/research/haptic-mouse/" rel="alternate" type="text/html" title="Robot-Mediated haptics for blind students STEM education" /><published>2024-08-14T08:00:00-04:00</published><updated>2024-08-14T08:00:00-04:00</updated><id>https://shredlabcmu.github.io/research/haptic-mouse</id><content type="html" xml:base="https://shredlabcmu.github.io/research/haptic-mouse/">&lt;p&gt;Haptic Mouse is a prototype of a mouse that uses touch feedback to render digital graphical content for blind and low-vision users.  Our intent is to develop an open-source tool that aids blind and low-vision students in learning abstract concepts that are hard to grasp without visualizations.  Through our device, students can dynamically interact with abstract concepts such as mathematical functions, physical and chemical equations, among others using their sense of touch.&lt;/p&gt;
&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2022-05-02-haptic-blind/delta.png&quot; /&gt;
    &lt;figcaption&gt;
    Diagram of the Delta Robot mechanism used in the Haptic Mouse
    &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2022-05-02-haptic-blind/Haptic-Mouse.png&quot; /&gt;
    &lt;!-- &lt;img src=&quot;/img/posts/2022-05-02-haptic-blind/DeltaMech.png&quot; /&gt; --&gt;
    &lt;img src=&quot;/img/posts/2022-05-02-haptic-blind/PXL_20241001_174418556.MP.jpg&quot; /&gt;
    &lt;figcaption&gt;
        We have designed a mouse capable of rendering rich haptic effects through a delta mechanism which replaces the standard mouse button.
    &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;div class=&quot;video-wrapper&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/cMkF67OGzsE&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;div class=&quot;video-wrapper&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/eGMqdWkUY98&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;!-- https://youtube.com/shorts/eGMqdWkUY98?feature=share --&gt;
&lt;h3 id=&quot;contact&quot;&gt;Contact&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/team/michael/&quot;&gt;Woongseok (Michael) Han&lt;/a&gt; &lt;a href=&quot;mailto:woongseh@andrew.cmu.edu&quot;&gt;woongseh@andrew.cmu.edu&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/team/melisa/&quot;&gt;Melisa Orta Martinez&lt;/a&gt; - &lt;a href=&quot;mailto:mortamar@andrew.cmu.edu&quot;&gt;mortamar@andrew.cmu.edu&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>SHRED Lab</name></author><category term="research" /><summary type="html">Haptic Mouse is a prototype of a mouse that uses touch feedback to render digital graphical content for blind and low-vision users. Our intent is to develop an open-source tool that aids blind and low-vision students in learning abstract concepts that are hard to grasp without visualizations. Through our device, students can dynamically interact with abstract concepts such as mathematical functions, physical and chemical equations, among others using their sense of touch. Diagram of the Delta Robot mechanism used in the Haptic Mouse We have designed a mouse capable of rendering rich haptic effects through a delta mechanism which replaces the standard mouse button.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://shredlabcmu.github.io/img/posts/2022-05-02-haptic-blind/labels.png" /><media:content medium="image" url="https://shredlabcmu.github.io/img/posts/2022-05-02-haptic-blind/labels.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>