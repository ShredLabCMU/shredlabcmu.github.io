<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://shredlabcmu.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://shredlabcmu.github.io/" rel="alternate" type="text/html" /><updated>2025-12-15T23:02:02-05:00</updated><id>https://shredlabcmu.github.io/feed.xml</id><title type="html">SHREDLab</title><subtitle>Researching haptic technologies with social and educational impact at Carnegie Mellon University
</subtitle><entry><title type="html">Soft Magnetic Actuator</title><link href="https://shredlabcmu.github.io/research/soft/" rel="alternate" type="text/html" title="Soft Magnetic Actuator" /><published>2025-02-03T05:40:07-05:00</published><updated>2025-02-03T05:40:07-05:00</updated><id>https://shredlabcmu.github.io/research/soft-magnetic-actuators</id><content type="html" xml:base="https://shredlabcmu.github.io/research/soft/">&lt;p&gt;Soft Magnetic Actuator for Haptics.&lt;/p&gt;

&lt;p&gt;Current tactile haptic displays are either able to render tangential and normal forces in one area of actuation on the fingertip, or normal forces in multiple areas of independent actuation, but cannot provide different kinds of forces in multiple independent areas of actuation. We are currently fabricating actuators using very low modulus materials together with magnetic particles to create weakly polarized flexible magnets. These materials respond with attraction or repulsion depending on the direction of the applied magnetic field and can apply shear or normal forces depending on the placement of external electromagnets. We are also developing apparatuses in which to test these materials for efficacy in texture rendering.&lt;/p&gt;

&lt;figure&gt;
 &lt;img src=&quot;/img/posts/2022-11-08-soft-magnetic-actuators/fingertip_and_magnets.png&quot; alt=&quot;Tiltrotor VTOL&quot; /&gt;
&lt;/figure&gt;

&lt;!-- &lt;div class=&quot;video-wrapper&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/KCBxeJupIgk&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt; --&gt;
&lt;!-- &lt;div class=&quot;video-wrapper&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/KCBxeJupIgk&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt; --&gt;
&lt;div class=&quot;video-wrapper&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/KCBxeJupIgk&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;

&lt;h3 id=&quot;publications&quot;&gt;Publications&lt;/h3&gt;
&lt;p&gt;A Magnetic Soft Device for Tactile Haptic Actuation of the Fingertip.
By Costrell, S., Alam, M., Klatzky, R.L., McHenry, M.E., Walker, L.M. and Martinez, M.O. In 2023 IEEE World Haptics Conference (WHC), , pp. 48–55, , 2023. &lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/10224478&quot;&gt;IEEXplore link&lt;/a&gt;&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2022-11-08-soft-magnetic-actuators/user_study_setup.jpg&quot; /&gt;
    &lt;figcaption&gt;
       Setup for user study testing.
    &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2022-11-08-soft-magnetic-actuators/closer_magnet_ruler.gif&quot; /&gt;
    &lt;figcaption&gt;
        Interaction with the magnetic field.
    &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;contact&quot;&gt;Contact&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Sarah Costrell (MechE) &lt;a href=&quot;mailto:scostrel@andrew.cmu.edu&quot;&gt;(scostrel@andrew.cmu.edu)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>SHRED Lab</name></author><category term="research" /><summary type="html">Soft Magnetic Actuator for Haptics.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://shredlabcmu.github.io/img/posts/2022-11-08-soft-magnetic-actuators/fingertipandmagnet.jpg" /><media:content medium="image" url="https://shredlabcmu.github.io/img/posts/2022-11-08-soft-magnetic-actuators/fingertipandmagnet.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">RoboLoom: Teach math through weaving</title><link href="https://shredlabcmu.github.io/research/roboloom-2025/" rel="alternate" type="text/html" title="RoboLoom: Teach math through weaving" /><published>2025-02-03T05:40:07-05:00</published><updated>2025-02-03T05:40:07-05:00</updated><id>https://shredlabcmu.github.io/research/roboloom</id><content type="html" xml:base="https://shredlabcmu.github.io/research/roboloom-2025/">&lt;p&gt;RoboLoom is a robotic Jacquard loom kit designed to facilitate interdisciplinary learning in engineering, mathematics, and art through collaborative assembly and use. It allows students to work together on building and operating the loom, fostering teamwork while teaching key concepts in weaving, engineering, and linear algebra.
Most people don’t know how closely related computers, matrices, and the craft of weaving are, but weaving patterns and early loom designs inspired some of early computing and matrices. For today’s looms and computers there is still a connection. Matrices can describe how a loom is threaded, and what actions are taken each time step while weaving. These matrices can then be multiplied together resulting in a cloth’s pattern. Designing and optimizing these matrices can be explored as a computational problem in a crafting framework. 
In addition, the woven cloth itself can be engineered using mathematical properties of the matrix representation of the cloth. These physical properties can predict how the cloth can be used and the strength it will have. Furthermore, advancements in engineering have been inspired by looms as they’ve been engineered to hold tension and become more autonomous machines. 
RoboLoom aims to explore these interrelated concepts and bring weaving, matrix math, and engineering together in the classroom in new and interesting ways.&lt;/p&gt;

&lt;!-- &lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-02-03-roboloom/roboloom_side_unedited.jpg&quot; /&gt;
    &lt;figcaption&gt;
        RoboLoom assembled.
    &lt;/figcaption&gt;
&lt;/figure&gt; --&gt;
&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-02-03-roboloom/students_working.png&quot; /&gt;
    &lt;figcaption&gt;
        Students working during the summer of 2024.
    &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-02-03-roboloom/RoboLooms_Class_S24.jpg&quot; /&gt;
    &lt;figcaption&gt;
        Render of the RoboLoom.
    &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-02-03-roboloom/tension_system.jpg&quot; /&gt;
    &lt;figcaption&gt;
        Roboloom tension system.
    &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-02-03-roboloom/JacquardMode Herringbone.png&quot; /&gt;
    &lt;figcaption&gt;
        GUI for weaving using our RoboLoom.
    &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;contact&quot;&gt;Contact&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/team/sam&quot;&gt;Samantha Speer&lt;/a&gt; snspeer@andrew.cmu.edu&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/team/will/&quot;&gt;Will Scott&lt;/a&gt; wscott2@andrew.cmu.edu&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Our dedicated website at: &lt;a href=&quot;https://sites.google.com/view/roboloom/&quot;&gt;https://sites.google.com/view/roboloom/&lt;/a&gt;&lt;/p&gt;</content><author><name>SHRED Lab</name></author><category term="research" /><summary type="html">RoboLoom is a robotic Jacquard loom kit designed to facilitate interdisciplinary learning in engineering, mathematics, and art through collaborative assembly and use. It allows students to work together on building and operating the loom, fostering teamwork while teaching key concepts in weaving, engineering, and linear algebra. Most people don’t know how closely related computers, matrices, and the craft of weaving are, but weaving patterns and early loom designs inspired some of early computing and matrices. For today’s looms and computers there is still a connection. Matrices can describe how a loom is threaded, and what actions are taken each time step while weaving. These matrices can then be multiplied together resulting in a cloth’s pattern. Designing and optimizing these matrices can be explored as a computational problem in a crafting framework. In addition, the woven cloth itself can be engineered using mathematical properties of the matrix representation of the cloth. These physical properties can predict how the cloth can be used and the strength it will have. Furthermore, advancements in engineering have been inspired by looms as they’ve been engineered to hold tension and become more autonomous machines. RoboLoom aims to explore these interrelated concepts and bring weaving, matrix math, and engineering together in the classroom in new and interesting ways.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://shredlabcmu.github.io/img/posts/2025-02-03-roboloom/RoboLoom.jpg" /><media:content medium="image" url="https://shredlabcmu.github.io/img/posts/2025-02-03-roboloom/RoboLoom.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">16-880: Engineering Haptic Interfaces</title><link href="https://shredlabcmu.github.io/teaching/ehi/" rel="alternate" type="text/html" title="16-880: Engineering Haptic Interfaces" /><published>2025-02-02T07:00:00-05:00</published><updated>2025-02-02T07:00:00-05:00</updated><id>https://shredlabcmu.github.io/teaching/ehi</id><content type="html" xml:base="https://shredlabcmu.github.io/teaching/ehi/">&lt;p&gt;This course focuses on addressing challenges in the field of haptics from an engineers perspective. We will begin by studying human haptic perception and an introduction into psychophysics. We will then study the design and control of haptic systems which provide touch feedback to a user. The class format will include lectures, discussion, paper presentations, laboratories and assignments using hardware that will be shipped to the students, and a class project. This class is designed to be a graduate/advanced undergraduate course and requires a background in dynamic systems, mechatronics, and basic programming. Mechanical prototyping, robotics, and feedback control knowledge are useful skills for this class but are not required.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-02-04-ehi/haptics.png&quot; /&gt;
    &lt;!-- &lt;figcaption&gt;
        Students working at the Hazelwood library.
    &lt;/figcaption&gt; --&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;instructor&quot;&gt;Instructor&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/_team/melisa&quot;&gt;Melisa Orta Martinez&lt;/a&gt; - &lt;a href=&quot;mailto:mortamar.andrew.cmu.edu&quot;&gt;mortamar@andrew.cmu.edu&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Melisa Orta Martinez</name></author><category term="teaching" /><summary type="html">This course focuses on addressing challenges in the field of haptics from an engineers perspective. We will begin by studying human haptic perception and an introduction into psychophysics. We will then study the design and control of haptic systems which provide touch feedback to a user. The class format will include lectures, discussion, paper presentations, laboratories and assignments using hardware that will be shipped to the students, and a class project. This class is designed to be a graduate/advanced undergraduate course and requires a background in dynamic systems, mechatronics, and basic programming. Mechanical prototyping, robotics, and feedback control knowledge are useful skills for this class but are not required.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://shredlabcmu.github.io/img/posts/2025-02-04-ehi/haptics.png" /><media:content medium="image" url="https://shredlabcmu.github.io/img/posts/2025-02-04-ehi/haptics.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">16-224 IDeATe: Re-Crafting Computational Thinking with Soft Technologies</title><link href="https://shredlabcmu.github.io/teaching/ideate/" rel="alternate" type="text/html" title="16-224 IDeATe: Re-Crafting Computational Thinking with Soft Technologies" /><published>2025-02-02T07:00:00-05:00</published><updated>2025-02-02T07:00:00-05:00</updated><id>https://shredlabcmu.github.io/teaching/ideate-soft</id><content type="html" xml:base="https://shredlabcmu.github.io/teaching/ideate/">&lt;p&gt;Re-Crafting Computational Thinking with Soft Technologies focuses on teaching introductory concepts of Robotics, Mechatronics, and Computer Science using an arts-based approach. During the course, you will build a weaving robot, program it, and explore how weaving is connected to computer programming and matrix mathematics. You will also learn the history of weaving, how to design dynamic patterns, and how to extract the features of those patterns into mathematical equations and computer programs.&lt;/p&gt;

&lt;!-- This course included guest presentations from:

Kate O’Brien
Vernelle Noel
Sarah Khadraoui
Harrison Apple
Mygenet Harris --&gt;

&lt;p&gt;This course serves students with an interest in computer programming, mechatronics, and robotics, offering a unique interdisciplinary approach to these concepts. It is equally valuable for those with a passion for textiles, weaving, and art who aim to discover the intriguing connections between weaving, mathematics, and robotics. Our target audience encompasses students from various academic backgrounds, with a particular focus on attracting individuals from the College of Fine Arts and the Computer Science departments. Previously, the course has been offered once as a mini-course, and the enrolled students represented a diverse range of majors, including: Art History, Architecture, Electrical Engineering, Computer Science, Art.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-02-04-ideate-soft/hands-soft.jpeg&quot; /&gt;
    &lt;!-- &lt;figcaption&gt;
        Students working at the Hazelwood library.
    &lt;/figcaption&gt; --&gt;
&lt;/figure&gt;

&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-02-04-ideate-soft/collaboration.jpeg&quot; /&gt;
    &lt;!-- &lt;figcaption&gt;
        Students working at the Hazelwood library.
    &lt;/figcaption&gt; --&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;instructor&quot;&gt;Instructor&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/_team/melisa&quot;&gt;Melisa Orta Martinez&lt;/a&gt; - &lt;a href=&quot;mailto:mortamar.andrew.cmu.edu&quot;&gt;mortamar@andrew.cmu.edu&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://ideate.cmu.edu/about/people/participating-educators/olivia-robinson.html&quot;&gt;Olivia Robinson&lt;/a&gt; - &lt;a href=&quot;mailto:orobinso@andrew.cmu.edu&quot;&gt;orobinso@andrew.cmu.edu&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Melisa Orta Martinez</name></author><category term="teaching" /><summary type="html">Re-Crafting Computational Thinking with Soft Technologies focuses on teaching introductory concepts of Robotics, Mechatronics, and Computer Science using an arts-based approach. During the course, you will build a weaving robot, program it, and explore how weaving is connected to computer programming and matrix mathematics. You will also learn the history of weaving, how to design dynamic patterns, and how to extract the features of those patterns into mathematical equations and computer programs.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://shredlabcmu.github.io/img/posts/2025-02-04-ideate-soft/hands-soft.jpeg" /><media:content medium="image" url="https://shredlabcmu.github.io/img/posts/2025-02-04-ideate-soft/hands-soft.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Rescue Rollers</title><link href="https://shredlabcmu.github.io/research/rescue-rollers/" rel="alternate" type="text/html" title="Rescue Rollers" /><published>2025-02-01T07:00:00-05:00</published><updated>2025-02-01T07:00:00-05:00</updated><id>https://shredlabcmu.github.io/research/rescue-rollers</id><content type="html" xml:base="https://shredlabcmu.github.io/research/rescue-rollers/">&lt;p&gt;Rescue Rollers are centimeter scale robots designed to operate in unstructured environments for search and rescue. We are exploring how we can achieve robust locomotion with robots of this size after natural disasters. By leveraging their size and a suite of sensing capabilities, a swarm of Rescue Rollers can help first-responders safely and efficiently locate and recover survivors. Rescue Rollers are also part of a symbiotic system with vine robots. They provide steering and enhanced sensing capabilities, while the vine robots allow for efficient large scale locomotion and power for the centi-robots.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-02-01-rescue-rollers/ExplodedIsometric.png&quot; /&gt;
    &lt;!-- &lt;img src=&quot;/img/posts/2022-05-02-haptic-blind/DeltaMech.png&quot; /&gt; --&gt;
    &lt;figcaption&gt;
        Exploded Isometric View of our Rescue Roller.
    &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-02-01-rescue-rollers/Deploy.png&quot; /&gt;
    &lt;!-- &lt;img src=&quot;/img/posts/2022-05-02-haptic-blind/DeltaMech.png&quot; /&gt; --&gt;
    &lt;figcaption&gt;
       Deployment of our rescue roller using via Vine Robot.
    &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;!-- &lt;div class=&quot;video-wrapper&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/cMkF67OGzsE&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt; --&gt;
&lt;!-- &lt;div class=&quot;video-wrapper&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/eGMqdWkUY98&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt; --&gt;
&lt;!-- https://youtube.com/shorts/eGMqdWkUY98?feature=share --&gt;

&lt;h3 id=&quot;contact&quot;&gt;Contact&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/team/sidney/&quot;&gt;Sidney Nimako&lt;/a&gt; -  &lt;a href=&quot;mailto:snimakob@andrew.cmu.edu&quot;&gt;snimakob@andrew.cmu.edu&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/team/melisa/&quot;&gt;Melisa Orta Martinez&lt;/a&gt; - &lt;a href=&quot;mailto:mortamar@andrew.cmu.edu&quot;&gt;mortamar@andrew.cmu.edu&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>SHRED Lab</name></author><category term="research" /><summary type="html">Rescue Rollers are centimeter scale robots designed to operate in unstructured environments for search and rescue. We are exploring how we can achieve robust locomotion with robots of this size after natural disasters. By leveraging their size and a suite of sensing capabilities, a swarm of Rescue Rollers can help first-responders safely and efficiently locate and recover survivors. Rescue Rollers are also part of a symbiotic system with vine robots. They provide steering and enhanced sensing capabilities, while the vine robots allow for efficient large scale locomotion and power for the centi-robots.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://shredlabcmu.github.io/img/posts/2025-02-01-rescue-rollers/soft_rescue.png" /><media:content medium="image" url="https://shredlabcmu.github.io/img/posts/2025-02-01-rescue-rollers/soft_rescue.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Cooperative Exploration with Heterogeneous Robot Teams</title><link href="https://shredlabcmu.github.io/research/cooperative/" rel="alternate" type="text/html" title="Cooperative Exploration with Heterogeneous Robot Teams" /><published>2025-02-01T07:00:00-05:00</published><updated>2025-02-01T07:00:00-05:00</updated><id>https://shredlabcmu.github.io/research/cooperative-robots</id><content type="html" xml:base="https://shredlabcmu.github.io/research/cooperative/">&lt;p&gt;We investigate how a heterogeneous robot team can improve urban search and rescue methods in collapsed buildings caused by earthquakes. Two types of robots compose the team: a vine robot for climbing in narrow, vertical spaces and RESCUE Rollers for general mobility at a minimal cost. The unstructured nature of disaster sites demands diverse robotic capabilities to traverse narrow gaps, navigate fallen rubble, and collectively analyze their environment to provide optimal coverage. Through various simulations and experiments, we evaluate different team compositions and compare trade-offs with regard to cost versus coverage. These experiments highlight the benefits of combining varied robot types to formulate a team that can adapt to the many challenges in unstructured environments. Building on these insights, we will next conduct real life experiments and create navigation policies leveraging the robot team’s collaboration.&lt;/p&gt;

&lt;!-- &lt;figure&gt;
 &lt;img src=&quot;/img/posts/2022-03-07-haptic-guidance/Hand_render.JPG&quot;/&gt;
&lt;/figure&gt; --&gt;
&lt;div class=&quot;video-wrapper&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/rR4xNo3OONY&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;

&lt;h3 id=&quot;contact&quot;&gt;Contact&lt;/h3&gt;
&lt;!-- - [Woongseok (Michael) Han](https://shredlabcmu.github.io/team/michael/) (woongseh [at]andrew [dot] cmu [dot] edu)  --&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/team/guadalupe&quot;&gt;Guadalupe Bernal&lt;/a&gt; - &lt;a href=&quot;mailto:gbernal@andrew.cmu.edu&quot;&gt;gbernal@andrew.cmu.edu&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/team/melisa/&quot;&gt;Melisa Orta Martinez&lt;/a&gt; - &lt;a href=&quot;mailto:mortamar.andrew.cmu.edu&quot;&gt;mortamar@andrew.cmu.edu&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>SHRED Lab</name></author><category term="research" /><summary type="html">We investigate how a heterogeneous robot team can improve urban search and rescue methods in collapsed buildings caused by earthquakes. Two types of robots compose the team: a vine robot for climbing in narrow, vertical spaces and RESCUE Rollers for general mobility at a minimal cost. The unstructured nature of disaster sites demands diverse robotic capabilities to traverse narrow gaps, navigate fallen rubble, and collectively analyze their environment to provide optimal coverage. Through various simulations and experiments, we evaluate different team compositions and compare trade-offs with regard to cost versus coverage. These experiments highlight the benefits of combining varied robot types to formulate a team that can adapt to the many challenges in unstructured environments. Building on these insights, we will next conduct real life experiments and create navigation policies leveraging the robot team’s collaboration.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://shredlabcmu.github.io/img/posts/2025-02-04-cooperative-robots/cooperative.png" /><media:content medium="image" url="https://shredlabcmu.github.io/img/posts/2025-02-04-cooperative-robots/cooperative.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">HaptiClay: Crafting Polynomial Functions</title><link href="https://shredlabcmu.github.io/research/hapticlay/" rel="alternate" type="text/html" title="HaptiClay: Crafting Polynomial Functions" /><published>2025-01-02T07:00:00-05:00</published><updated>2025-01-02T07:00:00-05:00</updated><id>https://shredlabcmu.github.io/research/hapticlay</id><content type="html" xml:base="https://shredlabcmu.github.io/research/hapticlay/">&lt;p&gt;HaptiClay, a low-cost kinesthetic haptic interface that elevates the understanding of mathematics language by providing embodied non-verbal representations of math concepts. 
Our interface integrates four key components: a haptic device, a high-level simulation that communicates with a low-level controller for force and position updates, a low-level controller that executes the feedback from the simulation, and a visualization system that provides visual feedback corresponding to the haptic input.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2025-01-02-hapticlay/will.png&quot; /&gt;
    &lt;figcaption&gt;
        Student crafting a quadratic function using HaptiClay
    &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;contact&quot;&gt;Contact&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;/team/iqui&quot;&gt;Iqui Balam Heredia Marin&lt;/a&gt; - &lt;a href=&quot;mailto:iquibalh@andrew.cmu.edu&quot;&gt;iquibalh@andrew.cmu.edu&lt;/a&gt;&lt;/p&gt;</content><author><name>SHRED Lab</name></author><category term="research" /><summary type="html">HaptiClay, a low-cost kinesthetic haptic interface that elevates the understanding of mathematics language by providing embodied non-verbal representations of math concepts. Our interface integrates four key components: a haptic device, a high-level simulation that communicates with a low-level controller for force and position updates, a low-level controller that executes the feedback from the simulation, and a visualization system that provides visual feedback corresponding to the haptic input.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://shredlabcmu.github.io/img/posts/2025-01-02-hapticlay/will.png" /><media:content medium="image" url="https://shredlabcmu.github.io/img/posts/2025-01-02-hapticlay/will.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Robot-Mediated haptics for blind students STEM education</title><link href="https://shredlabcmu.github.io/research/haptic-mouse/" rel="alternate" type="text/html" title="Robot-Mediated haptics for blind students STEM education" /><published>2024-08-14T08:00:00-04:00</published><updated>2024-08-14T08:00:00-04:00</updated><id>https://shredlabcmu.github.io/research/haptic-mouse</id><content type="html" xml:base="https://shredlabcmu.github.io/research/haptic-mouse/">&lt;p&gt;Haptic Mouse is a prototype of a mouse that uses touch feedback to render digital graphical content for blind and low-vision users.  Our intent is to develop an open-source tool that aids blind and low-vision students in learning abstract concepts that are hard to grasp without visualizations.  Through our device, students can dynamically interact with abstract concepts such as mathematical functions, physical and chemical equations, among others using their sense of touch.&lt;/p&gt;
&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2022-05-02-haptic-blind/delta.png&quot; /&gt;
    &lt;figcaption&gt;
    Diagram of the Delta Robot mechanism used in the Haptic Mouse
    &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2022-05-02-haptic-blind/Haptic-Mouse.png&quot; /&gt;
    &lt;!-- &lt;img src=&quot;/img/posts/2022-05-02-haptic-blind/DeltaMech.png&quot; /&gt; --&gt;
    &lt;img src=&quot;/img/posts/2022-05-02-haptic-blind/PXL_20241001_174418556.MP.jpg&quot; /&gt;
    &lt;figcaption&gt;
        We have designed a mouse capable of rendering rich haptic effects through a delta mechanism which replaces the standard mouse button.
    &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;div class=&quot;video-wrapper&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/cMkF67OGzsE&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;div class=&quot;video-wrapper&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/eGMqdWkUY98&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;!-- https://youtube.com/shorts/eGMqdWkUY98?feature=share --&gt;
&lt;h3 id=&quot;contact&quot;&gt;Contact&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/team/michael/&quot;&gt;Woongseok (Michael) Han&lt;/a&gt; &lt;a href=&quot;mailto:woongseh@andrew.cmu.edu&quot;&gt;woongseh@andrew.cmu.edu&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/team/melisa/&quot;&gt;Melisa Orta Martinez&lt;/a&gt; - &lt;a href=&quot;mailto:mortamar@andrew.cmu.edu&quot;&gt;mortamar@andrew.cmu.edu&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>SHRED Lab</name></author><category term="research" /><summary type="html">Haptic Mouse is a prototype of a mouse that uses touch feedback to render digital graphical content for blind and low-vision users. Our intent is to develop an open-source tool that aids blind and low-vision students in learning abstract concepts that are hard to grasp without visualizations. Through our device, students can dynamically interact with abstract concepts such as mathematical functions, physical and chemical equations, among others using their sense of touch. Diagram of the Delta Robot mechanism used in the Haptic Mouse We have designed a mouse capable of rendering rich haptic effects through a delta mechanism which replaces the standard mouse button.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://shredlabcmu.github.io/img/posts/2022-05-02-haptic-blind/labels.png" /><media:content medium="image" url="https://shredlabcmu.github.io/img/posts/2022-05-02-haptic-blind/labels.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Wireless Communication PCB Design</title><link href="https://shredlabcmu.github.io/research/pcb-design/" rel="alternate" type="text/html" title="Wireless Communication PCB Design" /><published>2024-08-14T08:00:00-04:00</published><updated>2024-08-14T08:00:00-04:00</updated><id>https://shredlabcmu.github.io/research/pcb-design</id><content type="html" xml:base="https://shredlabcmu.github.io/research/pcb-design/">&lt;!-- Blind and low vision STEM education is hindered by an inability to engage with visual representations of STEM concepts. Our sense of touch provides us with a separate, distributed channel that could allow us to convey abstract STEM concepts non-visually. We propose using robot-mediated haptics to enable blind and low vision students to engage in STEM education through hands-on, interactive learning. --&gt;
&lt;p&gt;This projects was mainly developed during the summer of 2024 as part of the &lt;a href=&quot;https://riss.ri.cmu.edu/&quot;&gt;RISS program&lt;/a&gt; at Carnegie Mellon University by &lt;a href=&quot;/team/olivia&quot;&gt;Olivia Sobek&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Exploring the use of LoRa (Long Range) wireless communication for search-and-rescue missions. The system involves heterogeneous robot collaboration, utilizing centimeter-scale spherical robots that interface with an inflatable vine robot developed by Purdue University. These robots will work collectively to navigate and gather data in challenging environments. In this case, each spherical robot may carry specific sensors, and data will be transmitted wirelessly to a handheld receiver held by a rescue operator.&lt;/p&gt;

&lt;p&gt;The communication system leverages LoRa technology, which operates around 900 MHz and uses chirp spread spectrum (CSS) modulation. This technique ensures robust, interference-resistant communication over ranges of up to 10-15 kilometers (6-9 miles), making it well-suited for long-range, low-power, and low-data-rate applications.&lt;/p&gt;

&lt;p&gt;The design includes the development of three custom PCBs:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Receiver PCB: A handheld, wireless device equipped with an ATMEGA328 microcontroller, a LoRa module, and an OLED display to show live sensor data from the robots.&lt;/li&gt;
  &lt;li&gt;Transmitter 1 PCB: Mounted on a spherical robot, featuring an ATMEGA328, a LoRa module, and sensors for air quality (CCS811) and metal oxide gas detection (ENS160).&lt;/li&gt;
  &lt;li&gt;Transmitter 2 PCB: Also mounted on a spherical robot, incorporating an ATMEGA328, a LoRa module, a flammable gas sensor (MQS), and an I2S microphone.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The PCBs were designed to be compact, measuring 1–2 inches in each dimension, to match the scale of the robots. The initial design used 3.7-volt batteries and 3.3-volt regulators. However, after troubleshooting, Switched to 5-volt regulators and 7-volt batteries, as explained later in this report. Used Altium Designer to create schematics and layouts.&lt;/p&gt;

&lt;p&gt;Check out our &lt;a href=&quot;/img/posts/2024-08-20-pcb-design/rissposter.png&quot;&gt;poster&lt;/a&gt; and &lt;a href=&quot;/img/posts/2024-08-20-pcb-design/risspaper.pdf&quot;&gt;Working Paper Journal&lt;/a&gt; for more information.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2024-08-20-pcb-design/2024-RISS-SOBEK-Olivia-research.jpg&quot; /&gt;
    &lt;!-- &lt;img src=&quot;/img/posts/2022-05-02-haptic-blind/DeltaMech.png&quot; /&gt; --&gt;
    &lt;figcaption&gt;
        Our PCB mounted on a spherical robot.
    &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2024-08-20-pcb-design/design.png&quot; /&gt;
    &lt;!-- &lt;img src=&quot;/img/posts/2022-05-02-haptic-blind/DeltaMech.png&quot; /&gt; --&gt;
    &lt;figcaption&gt;
       PCB design.
    &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;!-- &lt;div class=&quot;video-wrapper&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/cMkF67OGzsE&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt; --&gt;
&lt;!-- &lt;div class=&quot;video-wrapper&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/eGMqdWkUY98&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt; --&gt;
&lt;!-- https://youtube.com/shorts/eGMqdWkUY98?feature=share --&gt;

&lt;h3 id=&quot;contact&quot;&gt;Contact&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/team/olivia/&quot;&gt;Olivia Sobek&lt;/a&gt; -  &lt;a href=&quot;mailto:osobeck@andrew.cmu.edu&quot;&gt;osobeck@andrew.cmu.edu&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/team/melisa/&quot;&gt;Melisa Orta Martinez&lt;/a&gt; - &lt;a href=&quot;mailto:mortamar@andrew.cmu.edu&quot;&gt;mortamar@andrew.cmu.edu&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>SHRED Lab</name></author><category term="research" /><summary type="html">This projects was mainly developed during the summer of 2024 as part of the RISS program at Carnegie Mellon University by Olivia Sobek.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://shredlabcmu.github.io/img/posts/2024-08-20-pcb-design/IMG_8759.jpg" /><media:content medium="image" url="https://shredlabcmu.github.io/img/posts/2024-08-20-pcb-design/IMG_8759.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Air Quality Monitoring Community Workshop</title><link href="https://shredlabcmu.github.io/air-quality/" rel="alternate" type="text/html" title="Air Quality Monitoring Community Workshop" /><published>2024-07-25T08:00:00-04:00</published><updated>2024-07-25T08:00:00-04:00</updated><id>https://shredlabcmu.github.io/airquality</id><content type="html" xml:base="https://shredlabcmu.github.io/air-quality/">&lt;h1 id=&quot;air-quality-monitoring&quot;&gt;Air Quality Monitoring&lt;/h1&gt;

&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2024-07-25-airquality/KIMG1208.JPG&quot; /&gt;
    &lt;figcaption&gt;
        Lab members working with the community.
    &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;
&lt;p&gt;We understand the city of Pittsburgh along with the greater Pittsburgh area has historically suffered from poor/hazardous air quality conditions, stemming from the prolific rise and fall of the US steel industry. However, despite previous economic initiatives to rectify the air quality of the region, we acknowledge the active ongoing harm to our neighborhood communities by the U.S. Steel facilities known as the Clairton Coke Works and the Irvin and Edgar Thomson steel mills [1]. We are motivated to empower our youth to learn fundamental engineering and software concepts to develop a cluster of air-quality monitoring units to better assess, record, and understand their built environment to make more informed decisions on their health and safety.
[1] Douglas H. Phelps, President and Executive Director, Phelps, D. H., &amp;amp; Director, P. and E. (2024, January 29). Cleaner Air in Steel City. The Public Interest Network. &lt;a href=&quot;https://publicinterestnetwork.org/articles/cleaner-air-in-steel-city/&quot;&gt;https://publicinterestnetwork.org/articles/cleaner-air-in-steel-city/&lt;/a&gt;&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;/img/posts/2024-07-25-airquality/KIMG1211.JPG&quot; /&gt;
    &lt;figcaption&gt;
        Our lab head, Melisa, helping out a community member.
    &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;contact&quot;&gt;Contact&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/team/will/&quot;&gt;William Scott&lt;/a&gt; &amp;lt;wscott2 [at] cmu [dot] edu&amp;gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>William Scott</name></author><category term="teaching" /><category term="highlights" /><summary type="html">Air Quality Monitoring</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://shredlabcmu.github.io/img/posts/2024-07-25-airquality/KIMG1208.JPG" /><media:content medium="image" url="https://shredlabcmu.github.io/img/posts/2024-07-25-airquality/KIMG1208.JPG" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>